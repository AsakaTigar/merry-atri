# ATRI - My Dear Moments - 模型信息及操作指南

> 🎄 **最后更新**: 2025-12-25 02:25  
> 📊 **项目状态**: 数据集就绪，训练环境就绪

---

## ⚠️ 运行必读

**环境一定要激活 Aoduo！**
```bash
conda activate Aoduo
```
**⚠️ 严禁覆盖文件！**
- 所有生成的文件（模型权重、推理音频、日志）必须在文件名中包含时间戳或独立版本的标识。
- 禁止使用固定文件名（如 `output.wav`, `ATRI-e20.ckpt`）进行输出，以免覆盖之前的成果。


---

## 📋 工作日志
每次开始工作前，请务必查看并更新：
- **[工作日志情况.md](./工作日志情况.md)**
- 保持记录任何重大进展、报错或阻塞项。

---

## 🛡️ 环境验证
如果怀疑环境有问题，请运行：
```bash
python /mnt/t2-6tb/Linpeikai/Voice/ATRI/final_verify.py
```

---

## 📊 数据集信息 (已就绪 ✅)

| 项目 | 数量 | 路径 |
|------|------|------|
| 语音文件 (.opus) | 4,648 个 | `dataset/final_train/voices/` |
| 语音-文本对齐 | 4,629 条 | `dataset/final_train/final_dataset/` |
| GPT-SoVITS 训练集 | 2,154 条 | `dataset/gpt_sovits_train/` |

**角色分布**: ATRI 2,154 条 | 美奈子 608 条 | 龙司 585 条

---

## 🎵 语音模型训练 (GPT-SoVITS)

### 启动 WebUI
```bash
bash /mnt/t2-6tb/Linpeikai/Voice/ATRI/launch_gpt_sovits_train.sh
```
或直接访问: **http://10.23.23.93:7865**

### 训练数据路径
- **项目根目录**: `/mnt/t2-6tb/Linpeikai/Voice/ATRI`
- **原始数据源 (Read-Only)**: `/mnt/t2-6tb/Linpeikai/Voice/Voice_atri_mika` (包含完整解包的语音和文本)
- **导入工作区**: `/mnt/t2-6tb/Linpeikai/Voice/ATRI/dataset/phase2_import` (从源复制的JSON副本)
- **环境**: `conda activate Aoduo`
- **训练列表**: `/mnt/t2-6tb/Linpeikai/Voice/ATRI/dataset/gpt_sovits_train/train_list.txt`
- **WAV 文件**: `/mnt/t2-6tb/Linpeikai/Voice/ATRI/dataset/gpt_sovits_train/wavs/`

---

## 🧠 对话模型 (LLM) 操作

### 启动 LLaMA-Factory WebUI
```bash
bash /mnt/t2-6tb/Linpeikai/Voice/ATRI/launch_llama_factory.sh
```

### 🧠 启动 ATRI 对话模型微调 (Phase 2 - 自动化)
**一键启动 (数据处理 + 训练)**:
```bash
bash /mnt/t2-6tb/Linpeikai/Voice/ATRI/train_llm_master.sh
```
- **数据集**: 自动从 `.ks.json` 解析并注册为 `atri_sharegpt_YYYYMMDD_HHMMSS`
- **基座**: Qwen3-32B
### 训练 Qwen3-32B 特别说明
- **架构兼容性**: 虽然文件夹名为 Qwen3，但 `transformers` 库不认识 `qwen3` 类型。
- **Hack 方案**: 已手动将其 `config.json` 中的 `model_type` 改为 `qwen2`，`architectures` 改为 `Qwen2ForCausalLM` 以实现加载。**请勿在训练期间还原该文件。**
- **启动目录**: 必须在 `LLaMA-Factory` 根目录下执行 `llamafactory-cli`。


### 可用基座模型
| 模型 | 状态 | 路径 |
|------|------|------|
| DeepSeek-R1-32B | ✅ 就绪 | `weights/llm/DeepSeek-R1-Distill-Qwen-32B/` |
| Qwen3-32B | 🔄 下载中 | `weights/llm/Qwen3-32B-final/` |

---

## 🧠 长期记忆 (Mem0)
测试记忆系统：
```bash
python /mnt/t2-6tb/Linpeikai/Voice/ATRI/test_memory_logic.py
```

---

## 📂 关键目录说明

| 目录 | 说明 |
|------|------|
| `frameworks/` | So-VITS-SVC, GPT-SoVITS, LLaMA-Factory |
| `weights/` | 预训练权重 (LLM, ContentVec, UVR5) |
| `dataset/` | 训练数据集 |
| `raw_source/` | GitHub 项目源码 (merry-atri) |
| `logs/` | 训练日志 |

---

## 🔗 相关文档
- [ATRI_对话模型_可行性探讨.md](./ATRI_对话模型_可行性探讨.md)
- [ATRI_长期记忆系统设计.md](./ATRI_长期记忆系统设计.md)
- [ATRI_最佳拟合_项目计划书.md](./ATRI_最佳拟合_项目计划书.md)

---

## 🌐 Clash TUN 代理绕过配置

**背景**: 服务器开启了全局 TUN 模式代理 (Mihomo)，所有流量默认走代理。下载国内模型时需要绕过代理以节省流量。

**配置文件位置**: `/opt/clash/runtime.yaml`

**已添加直连的域名** (fake-ip-filter):
- 模型镜像: `modelscope.cn`, `hf-mirror.com`, `mistral.ai`
- 阿里系: `*.aliyuncs.com`, `*.aliyun.com`
- 清华镜像: `*.tsinghua.edu.cn`, `mirrors.tuna.tsinghua.edu.cn`
- 其他镜像: `*.ustc.edu.cn`, `*.huaweicloud.com`, `*.baidubce.com`
- 常用国内站点: `*.baidu.com`, `*.qq.com`, `*.bilibili.com` 等

**如需添加新域名到白名单**:
```bash
# 1. 编辑配置文件
sudo vim /opt/clash/runtime.yaml

# 2. 在 fake-ip-filter: 段落下添加域名，格式如:
#    - "example.com"
#    - "*.example.com"

# 3. 重启 Mihomo
sudo pkill mihomo && sudo nohup /opt/clash/bin/mihomo -d /opt/clash -f /opt/clash/runtime.yaml > /dev/null 2>&1 &

# 4. 验证 (应返回真实IP，非 198.18.x.x)
host example.com
```

**验证直连状态**:
```bash
# 返回 198.18.x.x = 走代理 (Fake IP)
# 返回真实IP (如 47.x.x.x) = 直连
host www.modelscope.cn
```

---

## 🛠️ 开源项目致谢
- **视觉小说解包**: [GARbro](https://github.com/morkt/GARbro)
- **音频切片**: [audio-slicer](https://github.com/flutydeer/audio-slicer)
- **干声分离**: [UVR5](https://github.com/Anjok07/ultimatevocalremovergui)
- **语音合成**: [GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)
- **语音转换**: [so-vits-svc](https://github.com/svc-develop-team/so-vits-svc)
- **LLM 微调**: [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)

---

> *"高性能ですから！"* 🎄
