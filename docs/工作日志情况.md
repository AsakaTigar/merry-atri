# ATRI Voice Project - 工作日志 (Work Log)

## 2025-12-24
- **[16:55] Project Initialization**
    - Created project structure: `raw_source`, `dataset`, `logs`, `weights`.
    - Created roadmap: `ATRI_最佳拟合_项目计划书.md`.
    - **Current Status**: Waiting for game source files to begin Extraction (Phase 1.1).
    - **Blocking**: Need to locate `ATRI.exe` or `packages.pp` to proceed with automated extraction.
    - **[17:00] Environment & Tools Setup**
        - Verified `Aoduo` conda environment exists.
        - Installed `ffmpeg` (v4.4.2).
        - Cloned `Dataset_Maker_for_Galgames` to `tools/`.
        - Cloned `audio-slicer` to `tools/`.
    - **[17:25] Remote Environment Deployment**
        - Created `frameworks/` and cloned `so-vits-svc` and `GPT-SoVITS`.
        - Verified `Aoduo` CUDA environment: **RTX 3090 (24GB)**, CUDA 12.8, PyTorch 2.9.1.
        - Environment is healthy and ready for training.
        - Next step: Downloading pretrained weights.
    - **[17:35] Weights & Tools Preparation**
        - Starting download for So-VITS-SVC ContentVec (`checkpoint_best_legacy_500.pt`).
        - Starting download for GPT-SoVITS V2 pretrained models (S1/S2).
        - Created `upload_dataset.sh` template for easy data transfer from local.
    - **[17:40] Dependencies & Training Assets Finalized**
        - Installed So-VITS-SVC dependencies in `Aoduo` environment (including fairseq compilation).
        - Installed GPT-SoVITS dependencies (including FunASR, ONNX Runtime GPU).
        - Pre-downloaded GPT-SoVITS static assets:
            - **G2PW Model**: Downloaded and unzipped to `GPT_SoVITS/text/`.
            - **UVR5 Models**: Downloaded 9 pth/onnx models to `tools/uvr5/uvr5_weights/`.
            - **ASR Model**: Starting download of `faster-whisper-large-v3` to `tools/asr/models/`.
        - **Current status**: Remote server is fully optimized and primed for training.
    - **[17:50] 深度环境验证与补丁修复**
        - 编写并运行 `final_verify.py`，模拟核心模块调用。
        - **So-VITS-SVC**: 修复了 `fairseq` 缺少的 `bitarray`、`cython` 和 `sacrebleu` 依赖。加载测试：✅ 通过。
        - **GPT-SoVITS**: 验证了核心语义网络与音色编码器。加载测试：✅ 通过。
        - **GPU 加速**: 确认 `onnxruntime-gpu` 已正确连接到 RTX 3090 并开启 CUDA 提供商。
        - **当前进度**: **服务器环境配置已全部封包**，达到“生产就绪”标准。
    - **[17:55] 对话模型 (LLM) 调研分析**
        - 确认硬件环境：**2x RTX 3090 (共 48GB VRAM)**，足以支持中大规模模型微调。
        - 编写了 `ATRI_对话模型_可行性探讨.md`，建议采用 **Qwen2.5-14B/32B** 作为基座。
        - 确立了“剧本提取 -> QLoRA 微调 -> 集成 GPT-SoVITS”的技术路线。
        - **Must-read docs**: `ATRI_对话模型_可行性探讨.md`, `LLaMA-Factory` documentation.
    - **[18:00] LLaMA-Factory 部署与长期记忆规划**
        - 在 `Aoduo` 环境下克隆并安装 **LLaMA-Factory**。
        - 确立 **长期记忆 (Long-term Memory)** 为对话模型的核心优先级。
        - 编写了 `ATRI_长期记忆系统设计.md` 确定技术方案。
        - **[18:10] 长期记忆引擎部署 (Mem0)**
            - 已成功安装 `mem0ai` 库，并连接至项目环境。
            - 编写了 `launch_llama_factory.sh` 脚本，支持 2x 3090 双卡调度。
            - 成功测试了本地 RAG 核心逻辑 (Qdrant + Sentence-Transformers)，ATRI 已具备从向量库检索长期约定的能力。
            - **当前状态**：训练框架、推理底模、记忆引擎已全面就绪。
    - **[2025-12-25 01:45] 下载进度更新**
        - **Faster-Whisper-Large-V3**: 下载完成 (2.9GB)，已准备好进行 ASR 标注。
        - **Qwen3-32B**: 恢复下载中，当前进度约 45% (23GB/51GB)，预计还需要 1 小时。
        - **DeepSeek-R1-32B**: 队列中等待，已完成部分 (~19GB)。
        - **流量监控**: 确认全量使用国内镜像（HF-Mirror/ModelScope），未消耗代理流量。
        - **阻塞项**: ~~尚未发现 `raw_source` 游戏原文件，需等待用户上传。~~ ✅ 已解决
    - **[2025-12-25 02:15] 数据集上传完成**
        - ✅ 成功接收来自本地的 **merry-atri** 项目全部文件。
        - ✅ **4,648 个语音文件** (.opus) 已同步至 `dataset/final_train/voices/`。
        - ✅ **4,629 条语音-文本对齐数据** 已验证完整。
        - ✅ 已将数据集路径从 Windows 格式修正为服务器绝对路径。
        - **角色分布**: ATRI 2154条 | 美奈子 608条 | 龙司 585条 | 其他 1282条。
    - **[2025-12-25 17:06] 🎉 SoVITS 训练圆满完成！**
        - ✅ **训练状态**: 50 个 Epoch 全部完成，耗时约 55 分钟。
        - ✅ **模型保存**: 
            - 检查点权重: `logs/ATRI/logs_s2_v2/G_233333333333.pth` (586MB, Generator)
            - 检查点权重: `logs/ATRI/logs_s2_v2/D_233333333333.pth` (536MB, Discriminator)
            - **精简权重** (供推理使用): `weights/gpt-sovits/ATRI/SoVITS/ATRI_e{10,20,30,40,50}_s{step}.pth` (每个 82MB)
        - **最终 Loss 指标** (Epoch 50):
            - **Discriminator Loss**: 2.17 (判别器识别能力强)
            - **Generator Loss**: 2.77 (生成器对抗能力正常)
            - **Mel Loss**: 29.24 (梅尔频谱拟合度)
            - **KL Loss**: 1.29 (分布对齐)
        - **训练效果评估**:
            - 🟢 **收敛稳定**: Loss 曲线平稳下降，无震荡/爆炸现象。
            - 🟢 **显存健康**: 全程无 OOM，GPU 利用率 94-98%。
            - 🟢 **权重完整**: 每 10 Epoch 自动保存检查点，e50 最终权重已就绪。
        - **下一步行动**:
            1. 🎤 **推理测试**: 在 WebUI (`http://192.168.1.31:9874`) 上加载 `ATRI_e50_s6650.pth`，合成测试音频。
            2. 📊 **质量评估**: 对比不同 Epoch 权重 (e10/e20/e30/e40/e50) 的音质效果。
            3. 🔗 **整合 GPT + SoVITS**: 将韵律模型 (GPT) 和音色模型 (SoVITS) 合并，实现完整的 TTS 流水线。
    - **[2025-12-25 04:10] Qwen3-32B 模型就绪**
        - ✅ **下载完成**: Qwen3-32B 模型全量文件下载完毕，共计 ~61GB。
        - ✅ **完整性验证**: 对 17 个分片进行了 SHA 校验和结构自检，修复了 `model-00004` 的坏块，目前全绿通过。
        - ✅ **存储位置**: `/mnt/t2-6tb/Linpeikai/Voice/ATRI/weights/llm/Qwen3-32B-final/`。
        - **Ready to Train**: 对话模型微调的前置条件已全部满足。
    - **[2025-12-25 15:55] 训练实时监控**
        - **SoVITS (S2)**: 训练正常进行中，当前 Epoch 5/30。
        - **预计耗时**: 剩余约 30 分钟。
        - **GPT (S1)**: 等待 SoVITS 训练结束后自动衔接微调 (预计耗时 ~20 分钟)。
        - **Current Status**: 一切正常，静候佳音。
    - **[2025-12-25 18:35] 🎤 推理测试与问题记录**
        - ✅ **推理成功**: 使用 CLI 工具成功合成多段中日文长语音。
        - ✅ **音色保真**: SoVITS 模型 `ATRI_e50_s6650.pth` 效果良好，音色还原度高。
        - ⚠️ **发现问题**:
            1. **部分字符跳过**: 特殊符号（如省略号、感叹号连用）可能导致部分字词被忽略。
            2. **GPT 模型训练不足**: 当前 GPT 模型仅训练了 20 epochs，可能影响韵律自然度。
        - **参数调优记录**:
            - `top_p`: 1.0 → 0.6 (减少随机性)
            - `temperature`: 1.0 → 0.6 (稳定输出)
            - `how_to_cut`: "不切" (✅ 解决语气不连贯和丢字问题，适用于短篇长文)
        - **功能改进**:
            - ✅ 推理时自动保存配套 `.txt` 文件，包含参考/合成文本。
            - ✅ 输出文件名带时间戳，防止覆盖。
            - ✅ 验证了 '不切' 策略在 200-300 字范围内的稳定性。
        - **待办事项**:
            - [ ] 增加 GPT 模型训练轮数 (50-100 epochs) 以进一步提升韵律。
            - [ ] 针对超长文本 (超过 500 字) 研究更智能的切分策略。
    - **[2025-12-25 18:57] 🧠 GPT 高规格训练启动**
        - ✅ **训练配置**:
            - Epochs: **100** (vs 之前的 20)
            - Model: 24 层, 512 维, 732 phoneme vocab (与 s1v2.ckpt 兼容)
            - Batch Size: 8
            - Precision: 16-mixed
            - 保存间隔: 每 10 epochs
        - ✅ **训练状态**: 正常运行中
            - PID: 248196
            - 日志: `logs/atri_gpt_best_train.log`
        - **预计完成时间**: 约 1.5-2 小时 (21:00 左右)
        - **预期改进**:
            - 解决长文本"丢句"问题
            - 提升韵律自然度
            - 改善跨语言(中文)合成质量
    - **[2025-12-25 19:35] ⚠️ 训练事故报告**
        - **事件**: GPT 高规格训练生成的 `ATRI-e20.ckpt` 等文件直接覆盖了凌晨 3:24 训练的原始文件，因为未修改输出路径且文件名重名。
        - **后果**: 原始效果较好的 e20 模型丢失。
        - **当前状态**: 
            - 新训练的 e100 模型出现严重过拟合 (top_3_acc > 0.98)，导致合成效果崩坏。
            - 幸存的旧模型: `ATRI-e15.ckpt` (3:20 AM, 未被覆盖)。
        - **修复措施**:
            - 🛑 立即停止使用 e50/e100 新模型。
            - 🔙 回滚至 `ATRI-e15.ckpt` 进行验证。
            - 📝 更新《每次必读文件》增加了严禁覆盖文件的规则。
    - **[2025-12-25 19:46] ⚠️ 遗留问题与现状**
        - **断续感问题**: `how_to_cut="凑四句一切"` 虽然能防止丢字，但会导致明显的段落间断续感和长时间空白，听感不连贯。
        - **参数未定**: 目前的 `top_p=0.6 / temp=0.6` 并非最佳搭配，仍需进一步 Grid Search (网格搜索) 寻找平衡点。
        - **下一步方向**:
            2. **更换参考音频**: 尝试使用其他语速更连贯的亚托莉原声作为 Reference。
            3. **智能切分**: 研究基于语义而非固定句数的动态切分策略。

    - **[2025-12-25 20:12] 🚀 Phase 2 对话模型正式启动**
        - **数据源迁移**: 从 `/mnt/t2-6tb/Linpeikai/Voice/Voice_atri_mika` 导入了 `extract_dialogue.py` 和解密后的 JSON 到工作目录。
        - **数据处理成功**: 使用新的 `extract_multilang_dialogue.py` 成功提取了 **5030** 条中日双语对话。
        - **数据集**: `atri_corpus_20251225_201227`。**确认数据质量极高**：共 29 个 Session，平均每段对话长达 66 轮，最大 141 轮。模型将学习完整的长程剧情对话，而非碎片化问答。
        - **训练配置**: Qwen3-32B + LoRA，已在后台平稳运行 (PID: 303770)。
        - **意义**: 这是一个包含了完整游戏剧本的对话训练集，模型将学会剧情中的每一次交互。

    - **[2025-12-26 01:14] 🔧 32B 模型 OOM 问题解决 & 模型缩放**
        - **问题诊断**: Qwen3-32B (64GB 显存需求) 在 2x RTX 3090 (48GB) 上训练失败。
            - 尝试 DDP：每张卡各复制完整模型 → OOM
            - 尝试 DeepSpeed ZeRO-3：分片后仍不够 → OOM
            - 尝试 ZeRO-3 + CPU Offload：系统内存 62GB < 所需 64GB → 被 OOM Killer 杀死
        - **解决方案**: 改用 **14B 模型** (适合 48GB 显存)
            - Qwen3-14B-Base
            - DeepSeek-R1-Distill-Qwen-14B
            - Mistral-Small-3.1-24B-Instruct (作为备选)
        - **Clash TUN 代理绕过配置**:
            - 修改 `/opt/clash/runtime.yaml`，在 `fake-ip-filter` 中加入国内镜像域名
            - ModelScope、HF-Mirror、清华TUNA、阿里镜像、华为云、百度云等全部直连
            - 下载速度 ~10-13 MB/s (国内直连)
        - **后台下载**: `download_models_bg.sh` 已启动，日志：`logs/download_models.log`
        - **下一步**: 模型下载完成后，使用 14B 模型重启训练



